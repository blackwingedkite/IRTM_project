{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from supabase import create_client, Client\n",
    "import os\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "model_name = \"text-embedding-3-small\"\n",
    "openai_api_key = os.environ['OPENAI_API_KEY']\n",
    "supabase_url = os.environ['SUPABASE_URL']\n",
    "supabase_api_key = os.environ['SUPABASE_API_KEY'] \n",
    "supabase: Client = create_client(supabase_url, supabase_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 請注意，目前的supabase預設只會回傳1000筆資料，若要一口氣拿到所有資料可以考慮\n",
    "1. 用我下面這塊程式碼的方法\n",
    "2. https://github.com/orgs/supabase/discussions/3765"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3493\n"
     ]
    }
   ],
   "source": [
    "page_size = 1000\n",
    "offset = 0\n",
    "all_data = []\n",
    "\n",
    "while True:\n",
    "    response = supabase.table('drcd_questions').select(\"embedding, paragraph_id\").range(offset, offset + page_size - 1).execute()\n",
    "    if not response.data:\n",
    "        break\n",
    "    all_data.extend(response.data)\n",
    "    offset += page_size\n",
    "question_embeddings = [ eval(x[\"embedding\"]) for x in all_data]\n",
    "gold_paragraph_ids = [x[\"paragraph_id\"] for x in all_data]\n",
    "\n",
    "print(len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension:\n",
      "1536\n"
     ]
    }
   ],
   "source": [
    "response2 = supabase.table('drcd_paragraphs').select(\"id, embedding\").eq(\"model\", model_name).execute()\n",
    "paragraph_ids = [x[\"id\"] for x in response2.data]\n",
    "paragraph_embeddings = [ eval(x[\"embedding\"]) for x in response2.data]\n",
    "\n",
    "print(\"Dimension:\")\n",
    "print( len(question_embeddings[0]) ) # 這是向量維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_index(arr, target):\n",
    "  try:\n",
    "      index = arr.index(target)\n",
    "      return index\n",
    "  except ValueError:\n",
    "      return \"not_found\"\n",
    "\n",
    "def calculate_average(arr):\n",
    "    if len(arr) == 0:\n",
    "        return 0  # 防止除以零錯誤\n",
    "    return sum(arr) / len(arr)\n",
    "\n",
    "def get_embeddings(input, model):\n",
    "  payload = { \"input\": input, \"model\": model }\n",
    "  headers = { \"Authorization\": f'Bearer {openai_api_key}', \"Content-Type\": \"application/json\" }\n",
    "  response = requests.post('https://api.openai.com/v1/embeddings', headers = headers, data = json.dumps(payload) )\n",
    "  obj = json.loads(response.text)\n",
    "  if response.status_code == 200 :\n",
    "    return obj[\"data\"][0][\"embedding\"]\n",
    "  else:\n",
    "    time.sleep(3)\n",
    "    print(\"embedding error..... retrying\")\n",
    "    # retry\n",
    "    return get_embeddings(input, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法一：用numpy的cosine similarty尋找最相似的內容並輸出結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 參數 list_of_doc_vectors 是所有文件的 embeddings 向量\n",
    "# 參數 query_vector 是查詢字串的 embedding 向量\n",
    "# 參數 top_k 是回傳的比數\n",
    "def cosine_similarity_search(list_of_doc_vectors, query_vector, top_k):\n",
    "  # 轉成 numpy arrays\n",
    "  list_of_doc_vectors = np.array(list_of_doc_vectors)\n",
    "  query_vector = np.array(query_vector)\n",
    "\n",
    "  # 逐筆計算 cosine similarities\n",
    "  similarities = cosine_similarity(query_vector.reshape(1, -1), list_of_doc_vectors).flatten()\n",
    "\n",
    "  # 根據 cosine similarity 排序\n",
    "  sorted_indices = np.argsort(similarities)[::-1]\n",
    "\n",
    "  # 取出 top K 的索引編號\n",
    "  top_k_indices = sorted_indices[:top_k]\n",
    "\n",
    "  return top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1   0 819  49 149]\n",
      "[  0   1 819   2 801]\n",
      "[  0 438 555 639 850]\n",
      "[  1   0  49 556  60]\n",
      "[  0   2   1 850 469]\n",
      "[  1   0 159   2 915]\n",
      "[  2 159 847  66 730]\n",
      "[  2 388 475 801 916]\n",
      "[  2 556 388 555 801]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "hit_data = []\n",
    "mmr_data = []\n",
    "for idx, question_embedding in enumerate(question_embeddings):\n",
    "\n",
    "  if idx%10 ==9:\n",
    "    print(idx)\n",
    "    break\n",
    "\n",
    "  best_indexes = cosine_similarity_search(paragraph_embeddings, question_embedding, 5) # 取出 top_k 的 indexes\n",
    "  print(best_indexes)\n",
    "#   context_ids = [paragraph_ids[i] for i in best_indexes] # 找出對應的 paragraph_ids\n",
    "#   hit_paragraph_id = gold_paragraph_ids[idx] # 這是黃金 paragraph_id\n",
    "\n",
    "#   position = find_index(context_ids, hit_paragraph_id)\n",
    "#   if position == \"not_found\":\n",
    "#     score = 0\n",
    "#   else:\n",
    "#     score = 1 / (position+1)\n",
    "\n",
    "#   mmr_data.append(score)\n",
    "#   hit_data.append(hit_paragraph_id in context_ids)\n",
    "\n",
    "# average_hit = sum(hit_data) / len(hit_data)\n",
    "\n",
    "# print(\"---------------------------\")\n",
    "# print(average_hit)\n",
    "\n",
    "# average_mrr = calculate_average(mmr_data)\n",
    "\n",
    "# print(\"MRR score:\")\n",
    "# print(average_mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- average score: 0.8685943315201832\n",
    "- MRR score: 0.7540843591945797\n",
    "- 時間：約5分鐘"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 方法2:使用langchain的vector search(基底也還是cosine similarity)\n",
    "\n",
    "我希望可以輸入問題的時候，去尋找drcd_paragraphs裡面最相關的top_k筆資訊\n",
    "\n",
    "以下是修改後的 SQL 函數，用於在 drcd_paragraphs 表格中搜索最相關的內容：\n",
    "```sql\n",
    "create function match_drcd_paragraphs (\n",
    "  query_embedding vector(1536),\n",
    "  top_k integer default 5\n",
    ") returns table (\n",
    "  content text,\n",
    "  similarity float\n",
    ") language plpgsql as $$\n",
    "begin\n",
    "  return query\n",
    "  select \n",
    "    content,\n",
    "    1 - (embedding <=> query_embedding) as similarity\n",
    "  from drcd_paragraphs\n",
    "  order by embedding <=> query_embedding\n",
    "  limit top_k;\n",
    "end;\n",
    "$$;\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import SupabaseVectorStore\n",
    "\n",
    "def langchain_vector_search_singleask(query, top_k=5):\n",
    "    # 獲取查詢的 embedding\n",
    "    query_embedding = get_embeddings(query, model_name)\n",
    "    \n",
    "    # 執行相似度搜索\n",
    "    response = supabase.rpc('match_drcd_paragraphs', {\n",
    "        'query_embedding': query_embedding,\n",
    "        'top_k': top_k\n",
    "    }).execute()\n",
    "    \n",
    "    return response.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>117</td>\n",
       "      <td>東方由於各個文明發端較早、文明發展呈連續性，各地保留有相當多、種類各異的貴族等級制度相關記載...</td>\n",
       "      <td>0.502288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>965</td>\n",
       "      <td>明清兩朝因有檔案留存，對於皇帝妃嬪人數有較為全面的了解。明朝嘉靖帝和清朝康熙帝分別是明清兩朝...</td>\n",
       "      <td>0.493501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>964</td>\n",
       "      <td>在中國歷代的史書中，由於妃嬪人數眾多，相較於皇后，通常對她們很難全部記錄。一位皇帝即使擁有眾...</td>\n",
       "      <td>0.491509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>905</td>\n",
       "      <td>元朝在推行漢人的典章制度與維護蒙古舊法之間，時常發生衝突，並且分裂成守舊派與崇漢派。早在元太...</td>\n",
       "      <td>0.460949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>786</td>\n",
       "      <td>朱棣稱帝後，六月十八，恢復了周王朱橚、齊王朱榑的爵位。隨後恢復代王朱桂、岷王朱楩的爵位。永樂...</td>\n",
       "      <td>0.459180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                            content  similarity\n",
       "0  117  東方由於各個文明發端較早、文明發展呈連續性，各地保留有相當多、種類各異的貴族等級制度相關記載...    0.502288\n",
       "1  965  明清兩朝因有檔案留存，對於皇帝妃嬪人數有較為全面的了解。明朝嘉靖帝和清朝康熙帝分別是明清兩朝...    0.493501\n",
       "2  964  在中國歷代的史書中，由於妃嬪人數眾多，相較於皇后，通常對她們很難全部記錄。一位皇帝即使擁有眾...    0.491509\n",
       "3  905  元朝在推行漢人的典章制度與維護蒙古舊法之間，時常發生衝突，並且分裂成守舊派與崇漢派。早在元太...    0.460949\n",
       "4  786  朱棣稱帝後，六月十八，恢復了周王朱橚、齊王朱榑的爵位。隨後恢復代王朱桂、岷王朱楩的爵位。永樂...    0.459180"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query = \"中國朝代有哪些？\"\n",
    "response = langchain_vector_search_singleask(query, top_k=5)\n",
    "\n",
    "# 構建一個清理好的 DataFrame\n",
    "result_data = []\n",
    "for i in response:\n",
    "    result_data.append({\n",
    "        'id': i.get('id', None),  # 如果 'id' 缺失，填 None\n",
    "        'content': i.get('content', None),\n",
    "        'similarity': i.get('similarity', None)\n",
    "    })\n",
    "result_pd = pd.DataFrame(result_data)\n",
    "result_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "print(len(question_embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 1, 819, 48, 150]\n",
      "[1, 2, 819, 3, 801]\n",
      "[1, 428, 552, 640, 849]\n",
      "[2, 1, 48, 553, 58]\n",
      "[1, 3, 2, 849, 460]\n",
      "[2, 1, 160, 3, 915]\n",
      "[3, 160, 846, 66, 730]\n",
      "[3, 377, 466, 801, 916]\n",
      "[3, 553, 377, 552, 801]\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "#正式進入評測環節\n",
    "hit_data = []\n",
    "mmr_data = []\n",
    "\n",
    "for idx, question_embedding in enumerate(question_embeddings):\n",
    "  if idx%10 == 9:\n",
    "    print(idx)\n",
    "    break\n",
    "  # 執行相似度搜索\n",
    "  response = supabase.rpc('match_drcd_paragraphs', {\n",
    "      'query_embedding': question_embedding,\n",
    "      'top_k': 5\n",
    "  }).execute()\n",
    "  best_indexes = []\n",
    "  for response in response.data:\n",
    "    best_indexes.append(response[\"id\"])\n",
    "  print(best_indexes)\n",
    "#   context_ids = [paragraph_ids[i] for i in best_indexes] # 找出對應的 paragraph_ids\n",
    "#   hit_paragraph_id = gold_paragraph_ids[idx] # 這是黃金 paragraph_id\n",
    "\n",
    "#   position = find_index(context_ids, hit_paragraph_id)\n",
    "#   if position == \"not_found\":\n",
    "#     score = 0\n",
    "#   else:\n",
    "#     score = 1 / (position+1)\n",
    "\n",
    "#   mmr_data.append(score)\n",
    "#   hit_data.append(hit_paragraph_id in context_ids)\n",
    "\n",
    "# average_hit = sum(hit_data) / len(hit_data)\n",
    "\n",
    "# print(\"---------------------------\")\n",
    "# print(average_hit)\n",
    "\n",
    "# average_mrr = calculate_average(mmr_data)\n",
    "\n",
    "# print(\"MRR score:\")\n",
    "# print(average_mrr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
